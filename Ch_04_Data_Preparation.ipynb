{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the Data"
      ],
      "metadata": {
        "id": "zHSar3WcIhLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzqO3JKBEj7n"
      },
      "outputs": [],
      "source": [
        "# Book Figure 4-1\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "nls97.head()\n",
        "nls97.tail()\n",
        "nls97.sample(10,random_state=3).T\n",
        "nls97[1000:1004].T\n",
        "nls97.index\n",
        "nls97.set_index(\"personid\", inplace=True)\n",
        "nls97.loc[[100061,100139,100284]].T # select based on index\n",
        "nls97.iloc[[0,1,2]].T # Select based on row number\n",
        "nls97.iloc[0:3].T # same as above\n",
        "nls97.iloc[-3:].T #last three\n",
        "nls97.loc[(nls97['gender']==\"Female\") & (nls97['maritalstatus']==\"Married\")]\n",
        "nls97.size\n",
        "nls97.shape\n",
        "nls97.dtypes\n",
        "nls97.info()\n",
        "nls97.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Data"
      ],
      "metadata": {
        "id": "YhEy3GrAIn3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "covidtotals = pd.read_csv(\"/content/drive/MyDrive/covidtotals.csv\")\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "print(covidtotals.isnull().sum(axis=0))\n",
        "covidtotals.total_cases_pm.fillna(covidtotals.total_cases/(covidtotals.population/1000000), inplace=True)\n",
        "covidtotals.total_deaths_pm.fillna(covidtotals.total_deaths/(covidtotals.population/1000000), inplace=True)\n",
        "covidtotals.isnull().sum(axis=0)\n",
        "\n",
        "nls97.birthmonth.fillna(int(nls97.birthmonth.mean()), inplace=True)# set a value for the missing data\n",
        "nls97new= nls97.dropna(thresh=2)# removes rows with less than two non-missing values\n",
        "nls97.wageincome.fillna(method='ffill', inplace=True)# replace missing values with the nearest non-missing value preceding\n"
      ],
      "metadata": {
        "id": "ZAqYMdi1JSe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inconsistency of Data"
      ],
      "metadata": {
        "id": "9V3q7UwyIwb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-3\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "nls97['birthyear'] = pd.to_numeric(nls97['birthyear'])\n",
        "nls97['gender'].value_counts()\n",
        "nls97.filter(like=\"colenr\").apply(lambda x:x.str[0:1]=='3').any(axis=1) # Use lambda to test several columns in one statement\n",
        "np.where(nls97.govprovidejobs.isnull(),np.nan,np.where(nls97.govprovidejobs.str.contains(\"not\"),\"No\",\"Yes\")) # pattern exists in a string.\n",
        "nls97.maritalstatus.str.startswith(' ').any()#leading space\n",
        "nls97.maritalstatus.str.endswith(' ').any()#tailing space\n",
        "nls97.maritalstatus = nls97.maritalstatus.str.lower()# Convert text to lowercase\n",
        "nls97.maritalstatus = nls97.maritalstatus.str.strip()# Remove leading/trailing whitespaces\n",
        "pd.concat([nls97.weeklyhrstv.head(), nls97.weeklyhrstv.str.findall(\"\\d+\").head()],axis=1)# extract numeric values from a text string\n"
      ],
      "metadata": {
        "id": "lBz92ALNDhBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conceptual Inconsistency"
      ],
      "metadata": {
        "id": "Palqr8U6Kdyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-4\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "#with post-graduate enrollment but no bachelor's enrollment\n",
        "nobach = nls97.loc[nls97.filter(like=\"colenr\").apply(lambda x: x.str[0:1]=='4').any(axis=1) & ~nls97.filter(like=\"colenr\").apply(lambda x: x.str[0:1]=='3').any(axis=1), \"colenrfeb97\":\"colenroct17\"]\n",
        "print(nobach.head())\n",
        "#wage income but no weeks worked\n",
        "nls97.loc[(nls97.weeksworked16==0) & nls97.wageincome>0, ['weeksworked16','wageincome']]\n",
        "# a high wage income.\n",
        "highwages = nls97.loc[nls97.wageincome >nls97.wageincome.mean()+(nls97.wageincome.std()*3),['wageincome']]\n",
        "print(highwages.head())\n",
        "# large changes in weeks worked for the most recent year\n",
        "workchanges = nls97.loc[~nls97.loc[:, \"weeksworked12\":\"weeksworked16\"].mean(axis=1). between(nls97.weeksworked17*0.5,nls97.weeksworked17*2)  & ~nls97.weeksworked17.isnull(),\"weeksworked12\":\"weeksworked17\"]\n",
        "workchanges.head()"
      ],
      "metadata": {
        "id": "RD4g5DG_s7_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicates"
      ],
      "metadata": {
        "id": "40lJM96sKmQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-5\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "nls97.set_index(\"personid\", inplace=True)\n",
        "print('data shape:',nls97.shape)\n",
        "print('unique indexes:',nls97.index.nunique()) # find unique index in personid\n",
        "print('duplicated data:',nls97.duplicated().value_counts()) # find duplicates in the database\n"
      ],
      "metadata": {
        "id": "58ZecjMNcEsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers"
      ],
      "metadata": {
        "id": "L7TCppCNJUKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Z-score, IQR, Scatter plot"
      ],
      "metadata": {
        "id": "O_y2JCIPJZFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-6\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "covidtotals = pd.read_csv(\"/content/drive/MyDrive/covidtotals.csv\")\n",
        "\n",
        "\n",
        "# Z Value approach\n",
        "z_scores = np.abs((nls97['wageincome'] - nls97['wageincome'].mean()) / nls97['wageincome'].std())\n",
        "outliers = nls97[z_scores > 3]\n",
        "print(outliers)\n",
        "\n",
        "# IQR approach\n",
        "thirdq,firstq=nls97['wageincome'].quantile(0.75),nls97['wageincome'].quantile(0.25)\n",
        "IQR=thirdq-firstq\n",
        "outlierhigh, outlierlow = 1.5*IQR+thirdq,firstq-1.5*IQR\n",
        "print(nls97['wageincome'].loc[(nls97['wageincome']>outlierhigh)|(nls97['wageincome']<outlierlow)])\n",
        "\n",
        "# Scatter plot and filter\n",
        "ax = sns.regplot(x=\"total_cases\", y=\"total_deaths\",data=covidtotals)\n",
        "covidtotals.loc[(covidtotals.total_cases_pm<7500)  & (covidtotals.total_deaths_pm>250), ['location','total_cases_pm','total_deaths_pm']]"
      ],
      "metadata": {
        "id": "LnzdYTTguf5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Box Plot"
      ],
      "metadata": {
        "id": "CcKEUjLkGCXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-9\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "plt.boxplot(nls97.satverbal.dropna())\n",
        "plt.ylabel(\"SAT Verbal\")\n",
        "plt.annotate('outlier threshold',xy=(1.05,780), xytext=(1.15,780), size=7,arrowprops=dict(facecolor='black', headwidth=2,width=0.5, shrink=0.02))\n",
        "plt.annotate('3rd quartile',xy=(1.08,570), xytext=(1.15,570), size=7,arrowprops=dict(facecolor='black', headwidth=2,width=0.5, shrink=0.02))\n",
        "plt.annotate('median', xy=(1.08,500),xytext=(1.15,500), size=7,arrowprops=dict(facecolor='black', headwidth=2,width=0.5, shrink=0.02))\n",
        "plt.annotate('1st quartile',xy=(1.08,430), xytext=(1.15,430), size=7,arrowprops=dict(facecolor='black', headwidth=2,width=0.5, shrink=0.02))\n",
        "plt.annotate('outlier threshold',xy=(1.05,220), xytext=(1.15,220), size=7,arrowprops=dict(facecolor='black', headwidth=2,width=0.5, shrink=0.02))\n"
      ],
      "metadata": {
        "id": "h5-GwqK3B3_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Violin Plot"
      ],
      "metadata": {
        "id": "R87DrVOtKfQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-10\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "sns.violinplot(nls97.satverbal, color=\"wheat\",orient=\"v\")\n",
        "plt.ylabel(\"SAT Verbal\")\n",
        "plt.text(0.08, 780, \"outlier threshold\", horizontalalignment='center', size='x-small')\n",
        "plt.text(0.065, nls97.satverbal.quantile(0.75), \"3rd quartile\", horizontalalignment='center', size='x-small')\n",
        "plt.text(0.05, nls97.satverbal.median(), \"Median\",horizontalalignment='center', size='x-small')\n",
        "plt.text(0.065, nls97.satverbal.quantile(0.25), \"1st quartile\", horizontalalignment='center', size='x-small')\n",
        "plt.text(0.08, 210, \"outlier threshold\",horizontalalignment='center', size='x-small')\n",
        "plt.text(-0.4, 500, \"frequency\",horizontalalignment='center', size='x-small')\n"
      ],
      "metadata": {
        "id": "qSkEOsxLGmxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) KNN"
      ],
      "metadata": {
        "id": "7hp_zGPlKjSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-11\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "covidtotals = pd.read_csv(\"/content/drive/MyDrive/covidtotals.csv\")\n",
        "\n",
        "!pip install pyod\n",
        "!pip installsklearn\n",
        "from pyod.models.knn import KNN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardizer = StandardScaler()\n",
        "analysisvars = ['location','total_cases_pm','total_deaths_pm', 'pop_density','median_age','gdp_per_capita']\n",
        "covidanalysis = covidtotals.loc[:, analysisvars].dropna()\n",
        "covidanalysisstand = standardizer.fit_transform(covidanalysis.iloc[:, 1:])\n",
        "clf_name = 'KNN'\n",
        "clf = KNN(contamination=0.1)\n",
        "clf.fit(covidanalysisstand)\n",
        "KNN(algorithm='auto', contamination=0.1, leaf_size=30,method='largest',metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,radius=1.0)\n",
        "y_pred = clf.labels_\n",
        "y_scores = clf.decision_scores_\n",
        "pred = pd.DataFrame(zip(y_pred, y_scores),columns=['outlier','scores'],index=covidanalysis.index)\n",
        "pred.sample(10, random_state=1)\n",
        "covidanalysis.join(pred).loc[pred.outlier==1,['location','total_cases_pm','total_deaths_pm','scores']].sort_values(['scores'], ascending=False)\n"
      ],
      "metadata": {
        "id": "UmM4TQQmKkSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformation"
      ],
      "metadata": {
        "id": "Sec-vGUoWKtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-13\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "# replacing values\n",
        "nls97['gender'].replace(['Female', 'Male'], [1, 2], inplace=True)\n",
        "print(nls97.head())\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "nls97_encoded = pd.get_dummies(nls97, columns=['gender'])\n",
        "nls97_encoded.head()\n"
      ],
      "metadata": {
        "id": "054WmVwwWQiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Balancing"
      ],
      "metadata": {
        "id": "VdQQaKdra4nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-15\n",
        "\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "matplotlib.style.use('fivethirtyeight')\n",
        "\n",
        "# data\n",
        "x = pd.DataFrame({\n",
        "\t# Distribution with lower outliers\n",
        "\t'x1': np.concatenate([np.random.normal(20, 2, 1000), np.random.normal(1, 2, 25)]),\n",
        "\t# Distribution with higher outliers\n",
        "\t'x2': np.concatenate([np.random.normal(30, 2, 1000), np.random.normal(50, 2, 25)]),\n",
        "})\n",
        "np.random.normal\n",
        "\n",
        "scaler = preprocessing.RobustScaler()\n",
        "robust_df = scaler.fit_transform(x)\n",
        "robust_df = pd.DataFrame(robust_df, columns =['x1', 'x2'])\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "standard_df = scaler.fit_transform(x)\n",
        "standard_df = pd.DataFrame(standard_df, columns =['x1', 'x2'])\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "minmax_df = scaler.fit_transform(x)\n",
        "minmax_df = pd.DataFrame(minmax_df, columns =['x1', 'x2'])\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols = 4, figsize =(20, 5))\n",
        "ax1.set_title('Before Scaling')\n",
        "ax1.set_xlabel('X1 , X2')\n",
        "\n",
        "sns.kdeplot(x['x1'], ax = ax1, color ='r')\n",
        "sns.kdeplot(x['x2'], ax = ax1, color ='b')\n",
        "ax2.set_title('After Robust Scaling')\n",
        "ax2.set_xlabel('X1 , X2')\n",
        "\n",
        "sns.kdeplot(robust_df['x1'], ax = ax2, color ='red')\n",
        "sns.kdeplot(robust_df['x2'], ax = ax2, color ='blue')\n",
        "ax3.set_title('After Standard Scaling')\n",
        "ax3.set_xlabel('X1 , X2')\n",
        "\n",
        "sns.kdeplot(standard_df['x1'], ax = ax3, color ='black')\n",
        "sns.kdeplot(standard_df['x2'], ax = ax3, color ='g')\n",
        "ax4.set_title('After Min-Max Scaling')\n",
        "ax4.set_xlabel('X1 , X2')\n",
        "\n",
        "sns.kdeplot(minmax_df['x1'], ax = ax4, color ='black')\n",
        "sns.kdeplot(minmax_df['x2'], ax = ax4, color ='g')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fym3uEZha7Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data creating and subsitution"
      ],
      "metadata": {
        "id": "n8h5Z5jICnnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Figure 4-16\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nls97 = pd.read_csv(\"/content/drive/MyDrive/nls97.csv\")\n",
        "\n",
        "# create new column/variable\n",
        "gpaoverall100 = nls97['gpaoverall'] * 100\n",
        "nls97['childnum'] = nls97.childathome + nls97. childnotathome\n",
        "\n",
        "# replacing new value in the dataframe\n",
        "nls97.childnum.value_counts().sort_index()\n",
        "nls97.iloc[0, 13] = 2\n",
        "nls97.set_index(\"personid\", inplace=True)\n",
        "nls97.loc[[100139,100284,100292],'gpaoverall'] = 0\n",
        "nls97.loc[nls97.gpaoverall>4, 'gpaoverall'] = 4\n",
        "nls97.weeklyhrscomputer.replace('None',0, inplace=True)\n",
        "nls97.weeklyhrscomputer.value_counts()\n",
        "\n",
        "#Delete column and rows\n",
        "nls97.drop(columns=\"childnum\")\n",
        "nls97.drop(labels=[100284,100292], axis=0)"
      ],
      "metadata": {
        "id": "2jvkL8QTCq9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}